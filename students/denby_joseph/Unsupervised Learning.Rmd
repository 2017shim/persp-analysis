---
title: "Unsupervised Learning"
author: "Jo Denby"
date: '`r Sys.Date()`'
output: github_document
---

####Colleges
```{r, message=FALSE}
library(tidyverse)
college <- read_csv("College.csv") %>%
  select(-Private)
```

#####1.
```{r}
pccollege <- prcomp(college, scale = TRUE)
biplot(pccollege, scale = 0)
```

Based on this biplot, the first principal component indicates that the variables with the strongest correlation are `Top 10Percent`, `Top 25Percent`, `Expend`, `Terminal`, `PhD`, and `Outstate`. For the second component, the `perc.alumni` and `Outstate` variables are those most strongly correlated with the principal component, with `F.Undergrad`, `Apps`, `Accept`, and `Enroll` having even stronger negative correlations.

#####2. 
```{r}
pccollege_var <- pccollege$sdev^2
pccollege_pve <- pccollege_var/sum(pccollege_var)
pccollege_pve
```
This vector describes the proportion of the dataset's variance explained by each of the 17 principal components.  
```{r}
pccollege_pve[1] + pccollege_pve[2]
```
By adding the first two values together, we can compute the proportion of the dataset's variance explained by the first two principal components (plotted above). The calculation shows that approximately 58% of the variance is explained by the first two components.

####States
```{r, message = FALSE, warning=FALSE}
arrests <- read_csv("USArrests.csv") %>%
  tibble::column_to_rownames("State")
```


#####1. 
```{r}
pcarrests <- prcomp(arrests, scale = TRUE)
biplot(pcarrests, scale = 0)

```

#####2.
```{r}
arrestsk2 <- kmeans(arrests, 2, nstart=20)
#pcarrestsk2 <- prcomp(arrestsk2, scale = TRUE)

#biplot(pcarrests, col = c(1,2), scale = TRUE)

```

#####5.
```{r}
pcarrests12 <- pcarrests$rotation %>%
  as.data.frame() %>%
  select(c("PC1", "PC2"))

# pcarrestsk2 <- kmeans(pcarrests12,3,nstart = 20)
# biplot(pcarrestsk2)
```
#####6.
```{r}
arrestshier <- hclust(dist(arrests), method = 'complete')
plot(arrestshier)
```

#####7. 
```{r}
plot(arrestshier)
abline(h=125, col = 'red')
```

By cutting at approximately 125, we group the states into three distinct clusters.  

Here, R outputs which state belongs to which cluster.  
```{r}
cutree(arrestshier,3)
```

#####8. 
```{r}
standarrests <- arrests %>%
  scale()

standarrestshier <- hclust(dist(standarrests), method = 'complete')
plot(standarrestshier)
```

